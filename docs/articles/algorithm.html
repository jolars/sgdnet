<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Technical Documentation • sgdnet</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Technical Documentation">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">sgdnet</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">0.0.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/algorithm.html">Technical Documentation</a>
    </li>
    <li>
      <a href="../articles/benchmarks.html">Benchmarks</a>
    </li>
    <li>
      <a href="../articles/cross-validation.html">Cross-Validation in sgdnet</a>
    </li>
    <li>
      <a href="../articles/introduction.html">An Introduction to sgdnet</a>
    </li>
    <li>
      <a href="../articles/models.html">Model Families in sgdnet</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/jolars/sgdnet">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Technical Documentation</h1>
                        <h4 class="author">Johan Larsson</h4>
            
            <h4 class="date">2018-08-13</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/jolars/sgdnet/blob/master/vignettes/algorithm.Rmd"><code>vignettes/algorithm.Rmd</code></a></small>
      <div class="hidden name"><code>algorithm.Rmd</code></div>

    </div>

    
    
<div id="background" class="section level2">
<h2 class="hasAnchor">
<a href="#background" class="anchor"></a>Background</h2>
<p><strong>sgdnet</strong> uses the incremental gradient method SAGA <span class="citation">(Defazio, Bach, and Lacoste-Julien 2014)</span>, which is a modification of the Stochastic Average Gradient (SAG) algorithm introduced in <span class="citation">Schmidt, Roux, and Bach (2017)</span>. SAGA handles both strongly and non-strongly convex objectives – even in the composite case – making it applicable to a wide range of problems such as generalized linear models with elastic net regularization <span class="citation">(Zou and Hastie 2005)</span>, which is the problem that <strong>sgdnet</strong> is designed to handle.</p>
<p>SAGA has a simple convergence proof and uses a step size that in fact adjusts automatically to the magnitude of strong convexity in the objective. This makes it practical for the end user, who avoids having to tune step size by hand.</p>
<p>The purpose of this vignette is to present the algorithm as it is implemented in <strong>sgdnet</strong> and to serve as guidance for anyone who is interested contributing to the development of the package.</p>
</div>
<div id="model-setup" class="section level2">
<h2 class="hasAnchor">
<a href="#model-setup" class="anchor"></a>Model setup</h2>
<p>Before the algorithm is set loose on data, its parameters have to be set up properly and its data (possibly) preprocessed. For illustrative purposes, we will proceed by example and use Gaussian univariate regression on the <code>trees</code> dataset. We will attempt to predict the volume of a tree based on girth and height.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1">x &lt;-<span class="st"> </span><span class="kw">with</span>(trees, <span class="kw">cbind</span>(Girth, Height))</a>
<a class="sourceLine" id="cb1-2" data-line-number="2">y &lt;-<span class="st"> </span>trees<span class="op">$</span>Volume</a></code></pre></div>
<div id="standardization" class="section level3">
<h3 class="hasAnchor">
<a href="#standardization" class="anchor"></a>Standardization</h3>
<p>By default, the feature matrix in <strong>sgdnet</strong> is centered and scaled to unit variance<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1">sgdnet_sd &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="kw">sqrt</span>(<span class="kw">sum</span>((x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x))<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span><span class="kw">length</span>(x))</a>
<a class="sourceLine" id="cb2-2" data-line-number="2">n &lt;-<span class="st"> </span><span class="kw">nrow</span>(x)</a>
<a class="sourceLine" id="cb2-3" data-line-number="3">x_bar &lt;-<span class="st"> </span><span class="kw">colMeans</span>(x)</a>
<a class="sourceLine" id="cb2-4" data-line-number="4">x_sd &lt;-<span class="st"> </span><span class="kw">apply</span>(x, <span class="dv">2</span>, sgdnet_sd)</a>
<a class="sourceLine" id="cb2-5" data-line-number="5">x &lt;-<span class="st"> </span><span class="kw">scale</span>(x, <span class="dt">center =</span> x_bar, <span class="dt">scale =</span> x_sd)</a></code></pre></div>
<p>In the univariate Gaussian case, we also standardize the response.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1">y_bar &lt;-<span class="st"> </span><span class="kw">mean</span>(y)</a>
<a class="sourceLine" id="cb3-2" data-line-number="2">y_sd &lt;-<span class="st"> </span><span class="kw">sgdnet_sd</span>(y)</a>
<a class="sourceLine" id="cb3-3" data-line-number="3">y &lt;-<span class="st"> </span>(y <span class="op">-</span><span class="st"> </span>y_bar)<span class="op">/</span>y_sd</a></code></pre></div>
</div>
<div id="regularization-path" class="section level3">
<h3 class="hasAnchor">
<a href="#regularization-path" class="anchor"></a>Regularization path</h3>
<p><strong>sgdnet</strong> supports <span class="math inline">\(\ell_1\)</span>- and <span class="math inline">\(\ell_2\)</span>-regularized regression as well as the elastic net, which is a linear combination of the two that is controlled by <span class="math inline">\(\alpha\)</span>, such that</p>
<p><span class="math display">\[\alpha = \frac{\lambda_2}{\lambda_1 + \lambda_2}\]</span></p>
<p>where <span class="math inline">\(\lambda_1\)</span> and <span class="math inline">\(\lambda_2\)</span> denotes the amount of <span class="math inline">\(\ell_1\)</span> and <span class="math inline">\(\ell_2\)</span> regularization respectively.</p>
<p>For our example, let’s say that we are fitting the elastic net with <span class="math inline">\(\alpha = 0.5\)</span>.</p>
<p>Typically, we fit a model along a path of <span class="math inline">\(\lambda\)</span>, beginning with <span class="math inline">\(\lambda_{max}\)</span>: the <span class="math inline">\(\lambda\)</span> at which the solution is completely sparse (save for the intercept, which is not regularized). It can be shown that</p>
<p><span class="math display">\[\lambda_{\text{max}} = 
  \max_{i}\frac{\langle\mathbf{x}_i, \mathbf{y}\rangle}{n\alpha}\]</span> Of course, when <span class="math inline">\(\alpha = 0\)</span> as in ridge regression, this value becomes undefined and so we constrain it so that <span class="math inline">\(\alpha \geq 0.001\)</span> in the computation of <span class="math inline">\(\lambda_{\text{max}}\)</span>.</p>
<p>For our example, we get the following.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1">alpha &lt;-<span class="st"> </span><span class="fl">0.5</span></a>
<a class="sourceLine" id="cb4-2" data-line-number="2">(lambda_max &lt;-<span class="st"> </span><span class="kw">max</span>(<span class="kw">abs</span>(<span class="kw">crossprod</span>(y, x)))<span class="op">/</span>(<span class="kw">max</span>(<span class="fl">0.001</span>, alpha)<span class="op">*</span>n))</a>
<a class="sourceLine" id="cb4-3" data-line-number="3"><span class="co">#&gt; [1] 1.934239</span></a></code></pre></div>
<p>We then construct the <span class="math inline">\(\lambda\)</span> path to be a <span class="math inline">\(\log_e\)</span>-spaced sequence starting at <span class="math inline">\(\lambda_{\text{max}}\)</span> and finishing at <span class="math inline">\(\lambda_{\text{max}} \times \lambda_{\text{min ratio}}\)</span>. Thus we have</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1">lambda.min.ratio &lt;-<span class="st"> </span><span class="fl">0.01</span></a>
<a class="sourceLine" id="cb5-2" data-line-number="2">nlambda &lt;-<span class="st"> </span><span class="dv">100</span></a>
<a class="sourceLine" id="cb5-3" data-line-number="3">lambda &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="kw">seq</span>(<span class="kw">log</span>(lambda_max),</a>
<a class="sourceLine" id="cb5-4" data-line-number="4">                  <span class="kw">log</span>(lambda_max<span class="op">*</span>lambda.min.ratio),</a>
<a class="sourceLine" id="cb5-5" data-line-number="5">                  <span class="dt">length.out =</span> nlambda))</a>
<a class="sourceLine" id="cb5-6" data-line-number="6"><span class="kw">head</span>(lambda)</a>
<a class="sourceLine" id="cb5-7" data-line-number="7"><span class="co">#&gt; [1] 1.934239 1.846325 1.762406 1.682302 1.605839 1.532851</span></a></code></pre></div>
<p><code>lambda.min.ratio</code> and <code>nlambda</code> are both setable through the API, but are given here at their defaults (per this example). Note that we return the lambda path on the original scale of the respone, <span class="math inline">\(\mathbf{y}\)</span>, which means that the user sees</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1">lambda_out &lt;-<span class="st"> </span>lambda<span class="op">*</span>y_sd</a>
<a class="sourceLine" id="cb6-2" data-line-number="2"><span class="kw">head</span>(lambda_out)</a>
<a class="sourceLine" id="cb6-3" data-line-number="3"><span class="co">#&gt; [1] 31.27770 29.85608 28.49907 27.20375 25.96729 24.78704</span></a></code></pre></div>
<p>Naturally, whatever value the user provides in the argument <code>lambda</code> to <code><a href="../reference/sgdnet.html">sgdnet()</a></code> will be scaled accordingly.</p>
</div>
<div id="step-size" class="section level3">
<h3 class="hasAnchor">
<a href="#step-size" class="anchor"></a>Step size</h3>
<p>The step size, <span class="math inline">\(\gamma\)</span>, in SAGA is constant throughout the algorithm. For non-strongly convex objectives it is set to <span class="math inline">\(1/(3L)\)</span>, where <span class="math inline">\(L\)</span> is the maximum Lipschitz constant of the term of the log-likelihood corresponding to a single observation. This is bound to be largest sample-wise squared norm of the feature matrix. For strongly convex objectives, the step size is set to</p>
<p><span class="math display">\[ \frac{1}{3(\mu n + L)},\]</span></p>
<p>where <span class="math inline">\(\mu\)</span> is the level of strong convexity and <span class="math inline">\(n\)</span> the number of samples. For our purposes, <span class="math inline">\(\mu\)</span>, is simply the regularization strength of the <span class="math inline">\(\ell_2\)</span>-penalty: <span class="math inline">\(\alpha\lambda\)</span>. This has the effect of letting the step size adapt to the type of regularization penalty used.</p>
<p>In our example, where we have the elastic net penalty, we will have the following step sizes (one for each <span class="math inline">\(\lambda\)</span>). For the sake of illustration, we will also include the case of ridge and lasso penalties to see the differences in step size.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1">reg &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>, <span class="dv">1</span>), <span class="cf">function</span>(alpha_i) {</a>
<a class="sourceLine" id="cb7-2" data-line-number="2">  lambda_<span class="dv">2</span> &lt;-<span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>alpha_i)<span class="op">*</span>lambda<span class="op">/</span>n <span class="co"># l2 penalty</span></a>
<a class="sourceLine" id="cb7-3" data-line-number="3">  L &lt;-<span class="st"> </span><span class="kw">max</span>(<span class="kw">rowSums</span>(x<span class="op">^</span><span class="dv">2</span>)) <span class="op">+</span><span class="st"> </span>lambda_<span class="dv">2</span></a>
<a class="sourceLine" id="cb7-4" data-line-number="4">  n &lt;-<span class="st"> </span><span class="kw">nrow</span>(x)</a>
<a class="sourceLine" id="cb7-5" data-line-number="5">  mu &lt;-<span class="st"> </span><span class="dv">2</span><span class="op">*</span>lambda_<span class="dv">2</span></a>
<a class="sourceLine" id="cb7-6" data-line-number="6">  step_size &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span>(<span class="dv">2</span><span class="op">*</span>(L <span class="op">+</span><span class="st"> </span><span class="kw">pmin</span>(mu<span class="op">*</span>n, L)))</a>
<a class="sourceLine" id="cb7-7" data-line-number="7">})</a>
<a class="sourceLine" id="cb7-8" data-line-number="8">reg &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(reg)</a>
<a class="sourceLine" id="cb7-9" data-line-number="9"><span class="kw">colnames</span>(reg) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">"ridge"</span>, <span class="st">"elastic_net"</span>, <span class="st">"lasso"</span>)</a>
<a class="sourceLine" id="cb7-10" data-line-number="10"></a>
<a class="sourceLine" id="cb7-11" data-line-number="11"><span class="kw">library</span>(lattice)</a>
<a class="sourceLine" id="cb7-12" data-line-number="12"><span class="kw"><a href="http://www.rdocumentation.org/packages/lattice/topics/xyplot">xyplot</a></span>(ridge <span class="op">+</span><span class="st"> </span>elastic_net <span class="op">+</span><span class="st"> </span>lasso <span class="op">~</span><span class="st"> </span><span class="kw">seq_len</span>(nlambda), </a>
<a class="sourceLine" id="cb7-13" data-line-number="13">       <span class="dt">data =</span> reg, <span class="dt">type =</span> <span class="st">"l"</span>,</a>
<a class="sourceLine" id="cb7-14" data-line-number="14">       <span class="dt">xlab =</span> <span class="ot">NULL</span>,</a>
<a class="sourceLine" id="cb7-15" data-line-number="15">       <span class="dt">ylab =</span> <span class="kw">expression</span>(gamma),</a>
<a class="sourceLine" id="cb7-16" data-line-number="16">       <span class="dt">auto.key =</span> <span class="kw">list</span>(<span class="dt">lines =</span> <span class="ot">TRUE</span>, <span class="dt">points =</span> <span class="ot">FALSE</span>, <span class="dt">space =</span> <span class="st">"right"</span>))</a></code></pre></div>
<div class="figure">
<img src="algorithm_files/figure-html/unnamed-chunk-7-1.png" alt="Step sizes along the regularization path." width="672"><p class="caption">
Step sizes along the regularization path.
</p>
</div>
</div>
</div>
<div id="algorithm" class="section level2">
<h2 class="hasAnchor">
<a href="#algorithm" class="anchor"></a>Algorithm</h2>
<p>We will now look at the implementation (in pseudocode) of the actual SAGA algorithm as it is realized in <strong>sgdnet</strong>.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1">y           response vector of size n</a>
<a class="sourceLine" id="cb8-2" data-line-number="2">X           feature matrix of size n<span class="op">*</span>p, each sample X[j] is stored columnwise</a>
<a class="sourceLine" id="cb8-3" data-line-number="3">beta        vector of coefficients of size p</a>
<a class="sourceLine" id="cb8-4" data-line-number="4">g_avg       gradient average</a>
<a class="sourceLine" id="cb8-5" data-line-number="5">l1          amount of L1<span class="op">-</span>regularization</a>
<a class="sourceLine" id="cb8-6" data-line-number="6">l2          amount of L2<span class="op">-</span>regularization</a>
<a class="sourceLine" id="cb8-7" data-line-number="7">max_iter    maximum number of outer iterations</a>
<a class="sourceLine" id="cb8-8" data-line-number="8">gamma       the step size</a>
<a class="sourceLine" id="cb8-9" data-line-number="9"></a>
<a class="sourceLine" id="cb8-10" data-line-number="10"><span class="cf">for</span> i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>max_iter</a>
<a class="sourceLine" id="cb8-11" data-line-number="11">  <span class="cf">for</span> k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_samples</a>
<a class="sourceLine" id="cb8-12" data-line-number="12">    X[j] &lt;-<span class="st"> </span>draw a sample randomly from X</a>
<a class="sourceLine" id="cb8-13" data-line-number="13">    </a>
<a class="sourceLine" id="cb8-14" data-line-number="14">    <span class="co"># Compute the conditional mean given X[j]</span></a>
<a class="sourceLine" id="cb8-15" data-line-number="15">    E[X] &lt;-<span class="st"> </span><span class="kw">DotProduct</span>(beta_scale<span class="op">*</span>beta, X[j])</a>
<a class="sourceLine" id="cb8-16" data-line-number="16">    </a>
<a class="sourceLine" id="cb8-17" data-line-number="17">    g_old    &lt;-<span class="st"> </span>g[j]</a>
<a class="sourceLine" id="cb8-18" data-line-number="18">    g_new    &lt;-<span class="st"> </span><span class="kw">Gradient</span>(E[X], y)</a>
<a class="sourceLine" id="cb8-19" data-line-number="19">    g_change &lt;-<span class="st"> </span>g_old <span class="op">-</span><span class="st"> </span>g_new</a>
<a class="sourceLine" id="cb8-20" data-line-number="20">    </a>
<a class="sourceLine" id="cb8-21" data-line-number="21">    <span class="co"># Perform l2-regularization by scaling beta</span></a>
<a class="sourceLine" id="cb8-22" data-line-number="22">    beta_scale &lt;-<span class="st"> </span>beta_scale<span class="op">*</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>gamma<span class="op">*</span>l2)</a>
<a class="sourceLine" id="cb8-23" data-line-number="23">    beta &lt;-<span class="st"> </span>beta[nz] <span class="op">-</span><span class="st"> </span>g_change<span class="op">*</span>gamma<span class="op">/</span>beta_scale</a>
<a class="sourceLine" id="cb8-24" data-line-number="24">    </a>
<a class="sourceLine" id="cb8-25" data-line-number="25">    <span class="co"># The gradient average step</span></a>
<a class="sourceLine" id="cb8-26" data-line-number="26">    X[j] &lt;-<span class="st"> </span><span class="kw">Update</span>(k <span class="op">+</span><span class="st"> </span><span class="dv">1</span>, </a>
<a class="sourceLine" id="cb8-27" data-line-number="27">                   nz,     </a>
<a class="sourceLine" id="cb8-28" data-line-number="28">                   X[j],</a>
<a class="sourceLine" id="cb8-29" data-line-number="29">                   g_avg,</a>
<a class="sourceLine" id="cb8-30" data-line-number="30">                   l1<span class="op">*</span>gamma<span class="op">/</span>beta_scale,     </a>
<a class="sourceLine" id="cb8-31" data-line-number="31">                   gamma<span class="op">/</span>beta_scale)</a>
<a class="sourceLine" id="cb8-32" data-line-number="32">    </a>
<a class="sourceLine" id="cb8-33" data-line-number="33">    <span class="co"># Update gradient average</span></a>
<a class="sourceLine" id="cb8-34" data-line-number="34">    g_avg &lt;-<span class="st"> </span>g_avg <span class="op">+</span><span class="st"> </span>g_change<span class="op">/</span>n_samples</a>
<a class="sourceLine" id="cb8-35" data-line-number="35">  </a>
<a class="sourceLine" id="cb8-36" data-line-number="36">  <span class="co"># At the end of each epoch, reset the scale and unlag all the coefficients</span></a>
<a class="sourceLine" id="cb8-37" data-line-number="37">  beta &lt;-<span class="st"> </span>beta<span class="op">*</span>beta_scale</a>
<a class="sourceLine" id="cb8-38" data-line-number="38">  beta_scale &lt;-<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb8-39" data-line-number="39">  </a>
<a class="sourceLine" id="cb8-40" data-line-number="40">  <span class="co"># Check convergence</span></a>
<a class="sourceLine" id="cb8-41" data-line-number="41">  <span class="cf">if</span> (<span class="kw">MaxChange</span>(beta)<span class="op">/</span><span class="kw">Max</span>(beta) <span class="op">&lt;</span><span class="st"> </span>thresh)</a>
<a class="sourceLine" id="cb8-42" data-line-number="42">    stop <span class="co"># algorithm has converged</span></a></code></pre></div>
<p>From this description we have left out the case where the scale of the coefficients becomes small enough to risk underflow and loss of numerical precision. In this case we simply rescale the coefficients back to their real scale (using <code>beta_scale</code>) and update all the coeffiecients that are lagging behind (if we have sparse features; see below for more information on this).</p>
<p>The algorithm for dense input is relatively straightforward. We</p>
<ol style="list-style-type: decimal">
<li>pick a sample uniformly at random,</li>
<li>compute the gradient at the current sample,</li>
<li>make the SAGA update to the coefficients using the gradient average, and</li>
<li>update the gradient average.</li>
</ol>
<p>Rinse and repeat until our convergence criterion is met.</p>
<div id="sparse-features" class="section level3">
<h3 class="hasAnchor">
<a href="#sparse-features" class="anchor"></a>Sparse features</h3>
<p>The implementation for sparse input, however, is slightly more intricate. The reason is that we can save considerable time by postponing the updates of coefficients when their corresponding features are sparse in the current sample. These “missed” or “lagged” updates can then be updated just-in-time when a sample is drawn that have non-sparse features corresponding to these coefficients or at the end of an epoch, at which point we make sure to update all of the coefficients to be able to check for convergence.</p>
<p>These lagged updates are accomplished in a <code>LaggedUpdate()</code> function, which relies on the following two objects:</p>
<dl>
<dt><code>lag_scaling</code></dt>
<dd>a vector storing the the cumulative geometric sums of the updates to the scale of the coefficients.
</dd>
<dt><code>lag</code></dt>
<dd>a vector of indices indicating which iteration the feature was last updated at.
</dd>
</dl>
<p>The definition of <code>LaggedUpdate()</code> is, roughly,</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="kw">LaggedUpdate</span>(k,                   <span class="co"># iteration</span></a>
<a class="sourceLine" id="cb9-2" data-line-number="2">             nz,                  <span class="co"># nonzero indices in current sample</span></a>
<a class="sourceLine" id="cb9-3" data-line-number="3">             beta,                <span class="co"># coefficients</span></a>
<a class="sourceLine" id="cb9-4" data-line-number="4">             g_avg,               <span class="co"># gradient average</span></a>
<a class="sourceLine" id="cb9-5" data-line-number="5">             prox_step_size</a>
<a class="sourceLine" id="cb9-6" data-line-number="6">             grad_step_size</a>
<a class="sourceLine" id="cb9-7" data-line-number="7">             lag,                </a>
<a class="sourceLine" id="cb9-8" data-line-number="8">             lag_scaling) {</a>
<a class="sourceLine" id="cb9-9" data-line-number="9">  </a>
<a class="sourceLine" id="cb9-10" data-line-number="10">  <span class="cf">for</span> i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(nz)</a>
<a class="sourceLine" id="cb9-11" data-line-number="11">    ind &lt;-<span class="st"> </span>nz[i] <span class="co"># index of nonzero feature</span></a>
<a class="sourceLine" id="cb9-12" data-line-number="12">    missed_updates &lt;-<span class="st"> </span>k <span class="op">-</span><span class="st"> </span>lag[ind]</a>
<a class="sourceLine" id="cb9-13" data-line-number="13">    </a>
<a class="sourceLine" id="cb9-14" data-line-number="14">    <span class="co"># L2-regularization</span></a>
<a class="sourceLine" id="cb9-15" data-line-number="15">    beta[ind] &lt;-<span class="st"> </span>beta[ind] <span class="op">+</span><span class="st"> </span>grad_step_size<span class="op">*</span>lag_scaling[missed_updates]<span class="op">*</span>g_avg[ind]</a>
<a class="sourceLine" id="cb9-16" data-line-number="16">    </a>
<a class="sourceLine" id="cb9-17" data-line-number="17">    <span class="co"># L1-regularization through SoftMax function.</span></a>
<a class="sourceLine" id="cb9-18" data-line-number="18">    beta[ind] &lt;-<span class="st"> </span><span class="kw">SoftThreshold</span>(beta[ind],</a>
<a class="sourceLine" id="cb9-19" data-line-number="19">                               prox_step_size<span class="op">*</span>lag_scaling[missed_updates])</a>
<a class="sourceLine" id="cb9-20" data-line-number="20">    </a>
<a class="sourceLine" id="cb9-21" data-line-number="21">    lag[ind] &lt;-<span class="st"> </span>k</a>
<a class="sourceLine" id="cb9-22" data-line-number="22">}</a></code></pre></div>
<p>where</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1"><span class="kw">SoftThreshold</span>(x, a) {</a>
<a class="sourceLine" id="cb10-2" data-line-number="2">  <span class="kw">max</span>(x <span class="op">-</span><span class="st"> </span>a, <span class="dv">0</span>) <span class="op">-</span><span class="st"> </span><span class="kw">max</span>(<span class="op">-</span>x <span class="op">-</span><span class="st"> </span>a, <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb10-3" data-line-number="3">}</a></code></pre></div>
</div>
</div>
<div id="unstandardization" class="section level2">
<h2 class="hasAnchor">
<a href="#unstandardization" class="anchor"></a>Unstandardization</h2>
<p>Coefficients from <strong>sgdnet</strong> are, irrespective of any internal standardizaton, always returned on the scale of the original data. Given our assumed model, we have.</p>
<p><span class="math display">\[\text{E}[\mathbf{Y}] = \beta_0 + \sum_{i=1}^p \beta_i\mathbf{x}_i\]</span></p>
<p>Using a standardized response and standardized features, we get the following estimation</p>
<p><span class="math display">\[
\frac{\hat{y} - \bar{y}}{s_y} =
  \hat{\beta}_0 +  \sum_{i=1}^p \hat{\beta}_i 
       \left( \frac{\mathbf{x}_i - \bar{x}_i}{s_{x_i}} \right),
\]</span></p>
<p>from which we retrieve the <em>unstandardized</em> intercept</p>
<p><span class="math display">\[
\hat{\beta}_{0_\text{unstandardized}} = \hat{\beta}_0 s_y + \bar{y} - \sum_{i=1}^p \hat{\beta}_i \frac{s_y}{s_{x_i}}\bar{x}_i
\]</span></p>
<p><span class="math display">\[
\hat{\beta}_{i_\text{unstandardized}} = \hat{\beta}_i \frac{s_y}{s_{x_i}}
\]</span></p>
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<div id="refs" class="references">
<div id="ref-defazio2014">
<p>Defazio, Aaron, Francis Bach, and Simon Lacoste-Julien. 2014. “SAGA: A Fast Incremental Gradient Method with Support for Non-Strongly Convex Composite Objectives.” In <em>Advances in Neural Information Processing Systems 27</em>, 2:1646–54. Montreal, Canada: Curran Associates, Inc.</p>
</div>
<div id="ref-schmidt2017">
<p>Schmidt, Mark, Nicolas Le Roux, and Francis Bach. 2017. “Minimizing Finite Sums with the Stochastic Average Gradient.” <em>Mathematical Programming</em> 162 (1-2): 83–112. <a href="https://doi.org/10/f9xwpn" class="uri">https://doi.org/10/f9xwpn</a>.</p>
</div>
<div id="ref-zou2005">
<p>Zou, Hui, and Trevor Hastie. 2005. “Regularization and Variable Selection via the Elastic Net.” <em>Journal of the Royal Statistical Society. Series B (Statistical Methodology)</em> 67 (2): 301–20.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr>
<ol>
<li id="fn1"><p>Here we use the <em>sample</em> standard deviation, dividing by <span class="math inline">\(n\)</span> rather than <span class="math inline">\(n-1\)</span>, since we are only interested in the sample at hand and not the entire population.<a href="#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#background">Background</a></li>
      <li><a href="#model-setup">Model setup</a></li>
      <li><a href="#algorithm">Algorithm</a></li>
      <li><a href="#unstandardization">Unstandardization</a></li>
      <li><a href="#references">References</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Johan Larsson, Toby Dylan Hocking, Michael Weylandt.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  

  </body>
</html>
