<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Cross-Validation in sgdnet • sgdnet</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Cross-Validation in sgdnet">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">sgdnet</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">0.0.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/algorithm.html">Technical Documentation</a>
    </li>
    <li>
      <a href="../articles/benchmarks.html">Benchmarks</a>
    </li>
    <li>
      <a href="../articles/cross-validation.html">Cross-Validation in sgdnet</a>
    </li>
    <li>
      <a href="../articles/introduction.html">An Introduction to sgdnet</a>
    </li>
    <li>
      <a href="../articles/models.html">Model Families in sgdnet</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/jolars/sgdnet">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Cross-Validation in sgdnet</h1>
                        <h4 class="author">Johan Larsson</h4>
            
            <h4 class="date">2018-08-13</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/jolars/sgdnet/blob/master/vignettes/cross-validation.Rmd"><code>vignettes/cross-validation.Rmd</code></a></small>
      <div class="hidden name"><code>cross-validation.Rmd</code></div>

    </div>

    
    
<p>Model validation is essential to both assess the performance<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> of a model and to be able to tune its parameters. <strong>sgdnet</strong> fits regularized models that are designed to avoid over-fitting. This, however, can only be accomplished if we split our data into training and test sets and tune our model by varying its parameters – in our case these is the regularization strength (<span class="math inline">\(\lambda\)</span>) and the elastic net mixing parameter (<span class="math inline">\(\alpha\)</span>) – and repeatedly fit our model against a training set and measure its performance against a test set.</p>
<p>There is a plethora of methods for model tuning. For <strong>sgdnet</strong> we have chosen to use <span class="math inline">\(k\)</span>-fold cross-validation, which is available via the <code><a href="../reference/cv_sgdnet.html">cv_sgdnet()</a></code> function. This function will randomly divide the data into <span class="math inline">\(k\)</span> folds. For each fold, the remaining <span class="math inline">\(k-1\)</span> will be used to train a model across a regularization path, and optionally a range of <span class="math inline">\(\alpha\)</span> (elastic net mixing parameters). The fold that is left out is then used to measure the performance of the model. We proceed across all the folds, which means that each observation is used exactly once for validation, and finally average our results across all the folds.</p>
<p>The end result is a tuned model with values for <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\alpha\)</span> chosen in a principled manner. We provide both <span class="math inline">\(\lambda_{min}\)</span>, which represents the model with the best performance and <span class="math inline">\(\lambda_{1SE}\)</span>, which gives the model with the largest <span class="math inline">\(\lambda\)</span> with an error within one standard deviation of that of the best model; choosing this <span class="math inline">\(\lambda\)</span> is often appropriate when the aim is to also achieve feature selection, because it often leads to a sparser model with only slightly worse performance. This is obviously not of value if <span class="math inline">\(\alpha = 0\)</span> so that the ridge penalty is in place and no coefficient will be sparse.</p>
<p>We’ll illustrate the cross-validation feature in <strong>sgdnet</strong> using the <code>heart</code> data set, where the aim is to classify a person as having or not having heart disease. In this case, we’ll also keep a separate validation set for a final performance check. First we’ll set up these sets.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">library</span>(sgdnet)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="kw">library</span>(Matrix)</a>
<a class="sourceLine" id="cb1-3" data-line-number="3"></a>
<a class="sourceLine" id="cb1-4" data-line-number="4"><span class="kw">set.seed</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb1-5" data-line-number="5">train_ind &lt;-<span class="st"> </span><span class="kw">ceiling</span>(<span class="kw">runif</span>(<span class="dv">270</span>, <span class="dv">0</span>, <span class="dv">270</span>))</a>
<a class="sourceLine" id="cb1-6" data-line-number="6">x_training &lt;-<span class="st"> </span>heart<span class="op">$</span>x[train_ind, ]</a>
<a class="sourceLine" id="cb1-7" data-line-number="7">y_training &lt;-<span class="st"> </span>heart<span class="op">$</span>y[train_ind]</a>
<a class="sourceLine" id="cb1-8" data-line-number="8">x_validation &lt;-<span class="st"> </span>heart<span class="op">$</span>x[<span class="op">-</span>train_ind, ]</a>
<a class="sourceLine" id="cb1-9" data-line-number="9">y_validation &lt;-<span class="st"> </span>heart<span class="op">$</span>y[<span class="op">-</span>train_ind]</a></code></pre></div>
<p>Next, we’ll use <code><a href="../reference/cv_sgdnet.html">cv_sgdnet()</a></code> to cross-validate and tune our model. We’ll try a range of elastic net penalties here and tune the model using misclassification error, by using <code>type.measure = "class"</code> in our call.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1">fit &lt;-<span class="st"> </span><span class="kw"><a href="../reference/cv_sgdnet.html">cv_sgdnet</a></span>(x_training, </a>
<a class="sourceLine" id="cb2-2" data-line-number="2">                 y_training,</a>
<a class="sourceLine" id="cb2-3" data-line-number="3">                 <span class="dt">family =</span> <span class="st">"binomial"</span>,</a>
<a class="sourceLine" id="cb2-4" data-line-number="4">                 <span class="dt">type.measure =</span> <span class="st">"class"</span>,</a>
<a class="sourceLine" id="cb2-5" data-line-number="5">                 <span class="dt">alpha =</span> <span class="kw">seq</span>(<span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="dt">by =</span> <span class="fl">0.1</span>))</a>
<a class="sourceLine" id="cb2-6" data-line-number="6"><span class="kw">plot</span>(fit)</a></code></pre></div>
<div class="figure">
<img src="cross-validation_files/figure-html/unnamed-chunk-2-1.png" alt="Results from model tuning using `cv_sgdnet()`." width="672"><p class="caption">
Results from model tuning using <code><a href="../reference/cv_sgdnet.html">cv_sgdnet()</a></code>.
</p>
</div>
<p>Our <code>fit</code> object also returns the model fit to the <span class="math inline">\(\alpha\)</span> with the best performance, here <span class="math inline">\(\alpha = 0.1\)</span>. We can now use this model together with the <span class="math inline">\(\lambda\)</span> corresponding to the best model, <span class="math inline">\(\lambda = 0.36\)</span> to make predictions on the validation data set we left out at the start. There is a dedicated method for <code>predict()</code> for this, which is largely there to make it convenient to predict based on the tuned <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\lambda\)</span>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1">predicted_classes &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, x_validation, <span class="st">"lambda_min"</span>, <span class="st">"class"</span>)</a></code></pre></div>
<p>We could of course use the results from <code>predict()</code> to measure the performance on the validation set. <strong>sgdnet</strong>, however, features a shortcut for this via the <code><a href="../reference/score.html">score()</a></code> function. For instance, the misclassification error for our validation set is then</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="kw"><a href="../reference/score.html">score</a></span>(fit, x_validation, y_validation, <span class="dt">s =</span> <span class="st">"lambda_min"</span>, <span class="dt">type.measure =</span> <span class="st">"class"</span>)</a>
<a class="sourceLine" id="cb4-2" data-line-number="2"><span class="co">#&gt;         1 </span></a>
<a class="sourceLine" id="cb4-3" data-line-number="3"><span class="co">#&gt; 0.1730769</span></a></code></pre></div>
<div class="footnotes">
<hr>
<ol>
<li id="fn1"><p>In truth, cross-validation does not provide a measure of test error in the <em>strict</em> sense but rather a decent approximation of it, which may be particularly useful if the data set analyzed is small.<a href="#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Johan Larsson, Toby Dylan Hocking, Michael Weylandt.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  

  </body>
</html>
