% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cv_sgdnet.R
\name{cv_sgdnet}
\alias{cv_sgdnet}
\title{\emph{k}-fold Cross Validation for \strong{sgdnet}}
\usage{
cv_sgdnet(x, y, alpha = 1, lambda = NULL, nfolds = 10,
  foldid = NULL, type.measure = c("deviance", "mse", "mae", "class",
  "auc"), ...)
}
\arguments{
\item{x}{input matrix}

\item{y}{response variable}

\item{alpha}{elastic net mixing parameter; vectors of values are allowed
(unlike in \code{\link[=sgdnet]{sgdnet()}})}

\item{lambda}{regularization strength}

\item{nfolds}{number of folds (\emph{k}) -- 3 is the minimum allowed}

\item{foldid}{a vector of fold identities of the same length as the
number of observations}

\item{type.measure}{the type of error, one of ("deviance" (default),
"mse" (mean-squared error), "mae" (mean absolute error), "class"
(misclassification rate), "auc" (area under the curve)); see \strong{Measures}
to find out what types each family has available.}

\item{...}{arguments passed on to \code{\link[=sgdnet]{sgdnet()}}}
}
\value{
An object of class \code{'cv_sgdnet'} with the following items:
\item{\code{alpha}}{the elastic net mixing parameter used}
\item{\code{lambda}}{a list of lambda values of the same length as \code{alpha}}
\item{\code{cv_summary}}{a \code{data.frame} summarizing the prediction error across
the regularization path with columns \code{alpha}, \code{lambda},
\code{mean}, \code{sd}, \code{ci_lo}, \code{ci_up}}
\item{\code{cv_raw}}{the raw cross-validation scores as a list of the
same length as \code{alpha}, each item a \code{matrix} with
the error for each fold as a row and each value of
\code{lambda} in columns.}
\item{\code{name}}{the type of prediction error used}
\item{\code{fit}}{a fit from \code{\link[=sgdnet]{sgdnet()}} to the full data set based on the
\code{alpha} with the best cross-validation score}
\item{\code{alpha_min}}{the \code{alpha} corresponding to the fit with the best
cross-validation performance}
\item{\code{lambda_min}}{the \code{lambda} corresponding to the fit with the best
cross-validation performance}
\item{\code{lambda_1se}}{the largest \code{lambda} with a cross-validation performance
within one standard deviation of the one
coresponding to \code{lambda_min}}
}
\description{
This function performs model validation by \emph{k}-fold cross validation for
models fit with \code{\link[=sgdnet]{sgdnet()}} over the entire regularization path and/or
various elastic net penalties.
}
\details{
The primary usage of this model is to tune for values of \code{lambda} and
\code{alpha}. This function will randomly divide the
data into \eqn{k} folds. For each fold, the remaining \eqn{k-1} will
be used to train a model across a regularization path, and optionally a
range of \code{alpha}. The fold that is left out
is then used to measure the performance of the model. We proceed across
all the folds, which means that each observation is used exactly once for
validation, and finally average our results across all the folds.
}
\section{Measures}{

\tabular{llllll}{
Family        \tab \code{deviance} \tab \code{mse} \tab \code{mae} \tab \code{class} \tab \code{auc}\cr
\code{gaussian}    \tab x (\code{mse})  \tab  x    \tab x     \tab         \tab      \cr
\code{binomial}    \tab x          \tab  x    \tab x     \tab x       \tab x    \cr
\code{multinomial} \tab x          \tab  x    \tab x     \tab x       \tab      \cr
\code{mgaussian}   \tab x (\code{mse})  \tab  x    \tab x     \tab         \tab
}
}

\examples{
set.seed(1)
n <- nrow(heart$x)
train_ind <- sample(n, floor(0.8*n))
cv_fit <- cv_sgdnet(heart$x[train_ind, ],
                    heart$y[train_ind],
                    family = "binomial",
                    nfolds = 7,
                    alpha = c(0, 1))
plot(cv_fit)
predict(cv_fit, heart$x[-train_ind, ], s = "lambda_min")
}
\seealso{
\code{\link[=sgdnet]{sgdnet()}}, \code{\link[=predict.cv_sgdnet]{predict.cv_sgdnet()}}, \code{\link[=plot.cv_sgdnet]{plot.cv_sgdnet()}}
}
\author{
Johan Larsson (partly consisting of modified code from
\code{\link[glmnet:cv.glmnet]{glmnet::cv.glmnet()}} by Jerome Friedman, Trevor Hastie, Rob Tibshirani,
and Noah Simon)
}
