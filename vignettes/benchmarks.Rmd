---
title: "Benchmarks"
author: "Johan Larsson"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Benchmarks}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

library(lattice)
library(latticeExtra)
library(sgdnet)

lattice.options(default.theme = list(fontsize = list(points = 4, text = 8)))

plot_benchmarks <- function(data) {
  p <- xyplot(loss ~ time | dataset + penalty,
              groups = package, 
              data = data,
              type = "l",
              auto.key = TRUE)
  useOuterStrips(p)
}
```

This vignette contains benchmarks of **sgdnet** against other similar
packages. The data has been precomputed from scripts that are
available at <https://github.com/jolars/sgdnet/data-raw/>.

The benchmarks were geneerated as follows:

* We fit ($\alpha = 1$) and ridge ($\alpha = 0$) regressions.
* The regularization strength, $\lambda$, was set to $1\n$ for each fit.
* A log-spaced sequence of tolerance thresholds were generated, which were
selected after trial-and-error to ensure that the packages exhibited
approximately the same behavior.
* The run times were recorded using `system.time()`.
* The range of run times were clipped to remove "trailing" times to make sure
that each the range of times for each package were constrained around the
same values.
* Both loss and run times were normalized and the latter were cut into
intervals of 20 slices within which the run times were averaged.

Note that some of the data sets below are not strictly 100% dense,
despite the specifications below. They are, however, stored in dense
matrix form (the regular `matrix` class in R), which makes the packages
ignore any sparsity.

## Gaussian least squares ordinary regression

Name              Observations      Features   Density
----------    ----------------     ---------   ---------
abalone                  4,177             8        100%
cadata                  20,640             8        100%
mushroooms               8,124            12        100%

Table: Benchmarking data sets for the gaussian model

```{r, fig.cap = "Benchmarking results for gaussian responses.", fig.width = 7, fig.height = 5}
plot_benchmarks(benchmarks$gaussian)
```


## Binomial logistic regression

In this section, we are going to look at the following datasets:

Name              Observations      Features   Density
----------    ----------------     ---------   ---------
adult                   32,561           123         11%
icjnn1                  49,990            22        100%
mushroooms               8,124           112         19%

Table: Benchmarking data sets for the binomial model.

All of these have been collected from the
[libsvm binary dataset collection](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html).

```{r, fig.cap = "Benchmarking results for binomial responses.", fig.width = 7, fig.height = 5}
plot_benchmarks(benchmarks$binomial)
```


## Multinomial logistic regression

For the multinomial model, we have these data sets:

Name              Observations   Classes   Features    Density
----------    ----------------   -------   ---------   ---------
segment                  2,310         7          19        100%  
dna                      2,000         3         180         25%
poker                   25,010        10          22        100%

Table: Benchmarking data sets for the multinomial model.

```{r, fig.cap = "Benchmarking results for multinomial responses.", fig.width = 7, fig.height = 5}
plot_benchmarks(benchmarks$multinomial)
```
